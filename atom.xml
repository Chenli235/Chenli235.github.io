<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://chenli235.github.io</id>
    <title>Chen Li</title>
    <updated>2020-03-27T02:48:16.660Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://chenli235.github.io"/>
    <link rel="self" href="https://chenli235.github.io/atom.xml"/>
    <subtitle>UNC &amp; NCSU Biomedical Imaging Lab</subtitle>
    <logo>https://chenli235.github.io/images/avatar.png</logo>
    <icon>https://chenli235.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, Chen Li</rights>
    <entry>
        <title type="html"><![CDATA[Assessing microscope image focus quality with deep learning]]></title>
        <id>https://chenli235.github.io/post/articles/</id>
        <link href="https://chenli235.github.io/post/articles/">
        </link>
        <updated>2020-03-22T09:02:25.000Z</updated>
        <content type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://chenli235.github.io/post-images/1585256740222.PNG" alt="" loading="lazy"></figure>
<h1 id="intereting-paper-about-assessing-microscope-image-quality">intereting paper about assessing microscope image quality</h1>
<p>this is the <a href="https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-018-2087-4">paper</a><br>
The advantage of the proposed method:</p>
<ol>
<li>Create dataset using only in-focus images, get out-of focus images by PSF.</li>
<li>we can generate dataset of different level of focus quality by moving focus distance.</li>
<li>directly neural network and source code are provided in this article.</li>
<li>the whole image can be divided into many small image pathes,  which accelerate the training speed.</li>
<li>the method has a imageJ plugin.</li>
<li>Data augmentation to handle noises and offset images</li>
</ol>
<h1 id="implementation">Implementation</h1>
<ol>
<li>Create an dataset of images consisting of both infocus and out of focus images of U2OS cancer cells with Hoechst stain.</li>
<li>Then defocus the infocus images by applying a convolution with the PSF(point spread function) by varying z in 2um increments.<br>
<img src="https://chenli235.github.io/post-images/1585258360693.PNG" alt="PSF" loading="lazy"><br>
J0 is the Bessel function, wavelength,numerical aperture, which are related with actual setup.</li>
<li>Apply Poisson noise, accounting for sensor offset.</li>
<li>Randomly pick 84$\times<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>84</mn><mi>i</mi><mi>m</mi><mi>a</mi><mi>g</mi><mi>e</mi><mi>c</mi><mi>r</mi><mi>o</mi><mi>p</mi><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>h</mi><mi>e</mi><mn>696</mn></mrow><annotation encoding="application/x-tex">84 image crops of the 696</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord">8</span><span class="mord">4</span><span class="mord mathdefault">i</span><span class="mord mathdefault">m</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord mathdefault">e</span><span class="mord mathdefault">c</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">o</span><span class="mord mathdefault">p</span><span class="mord mathdefault">s</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mord mathdefault">t</span><span class="mord mathdefault">h</span><span class="mord mathdefault">e</span><span class="mord">6</span><span class="mord">9</span><span class="mord">6</span></span></span></span>\times$520 original size image for training, for each patch, has 11 defocus levels.<br>
<img src="https://chenli235.github.io/post-images/1585260331255.PNG" alt="good image and defocused image" loading="lazy"></li>
</ol>
<p>the neural network model architecture and some of the result<br>
<a href="https://media.springernature.com/full/springer-static/image/art%3A10.1186%2Fs12859-018-2087-4/MediaObjects/12859_2018_2087_Fig2_HTML.gif?as=webp"></a><br>
The patch outlines have one of 11 hues denoting the predicted defocus level and increasing lightness denoting increased certainty.</p>
<h1 id="results">Results</h1>
<p><a href="https://media.springernature.com/full/springer-static/image/art%3A10.1186%2Fs12859-018-2087-4/MediaObjects/12859_2018_2087_Fig7_HTML.gif?as=webp"></a><br>
Prediction of absolute focus quality on an unseen cell type (MCF-7 cells, from BBBC021 dataset [12]) and unseen stain, Tubulin, using our Fiji (ImageJ) [20] plugin with pre-trained TensorFlow model. A composite image montage was assembled using the center 84‚Äâ√ó‚Äâ84 patch from a randomly selected batch of 240 images. The border hues denote predicted defocus levels (red for best focus), while the lightness denotes prediction certainty.</p>
<h1 id="check-the-mouse-brain-image-using-the-imagej-plugin">Check the mouse brain image using the imageJ plugin</h1>
<figure data-type="image" tabindex="2"><img src="https://chenli235.github.io/post-images/1585268654621.PNG" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="3"><img src="https://chenli235.github.io/post-images/1585268819733.PNG" alt="" loading="lazy"></figure>
<p>From the result, we can get the conclusion that on images patch that have shape edges, the prediction looks good but if the signal is too strong or protein material, it may predict as a out-of-focus image.</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mouse brain image using light sheet microscope]]></title>
        <id>https://chenli235.github.io/post/mouse-brain-image-using-light-sheet-microscope/</id>
        <link href="https://chenli235.github.io/post/mouse-brain-image-using-light-sheet-microscope/">
        </link>
        <updated>2020-03-21T13:34:17.000Z</updated>
        <content type="html"><![CDATA[<h1 id="hardware-setup">Hardware setup</h1>
<p><img src="https://chenli235.github.io/post-images/1585272993095.PNG" alt="" loading="lazy"><br>
<img src="https://chenli235.github.io/post-images/1585273628791.PNG" alt="" loading="lazy"></p>
<h1 id="mouse-brain-image">Mouse brain image</h1>
<p><img src="https://chenli235.github.io/post-images/1585275613220.PNG" alt="" loading="lazy"><br>
some common problem with light sheet microscope</p>
<ol>
<li>Intensity discontinuity<br>
<img src="https://chenli235.github.io/post-images/1585275853344.PNG" alt="" loading="lazy"><br>
it is due to the light bleaching and scattering.</li>
<li>Light Peneration issues (when using only one light path)<br>
<img src="https://chenli235.github.io/post-images/1585275983813.PNG" alt="" loading="lazy"><br>
<img src="https://chenli235.github.io/post-images/1585276033521.PNG" alt="" loading="lazy"></li>
</ol>
<h1 id="end">end</h1>
<p>it is my first experience with light sheet microscope, and I know the quality of image is not good enough. I will try different ways to improve the image quality and processing speed.</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[About me]]></title>
        <id>https://chenli235.github.io/post/about/</id>
        <link href="https://chenli235.github.io/post/about/">
        </link>
        <updated>2019-01-23T07:09:48.000Z</updated>
        <content type="html"><![CDATA[<blockquote>
<p>Welcome to my blog, nice to meet you here.</p>
</blockquote>
<h2 id="i-am-a-phd-student-in-unc-ncsu-state-joint-department-of-biomedical-engineering-my-research-area-is-medical-imging-and-microscope-design">üè† I am a PhD student in UNC &amp; NCSU State joint Department of  Biomedical Engineering. My research area is medical imging and microscope design.</h2>
<h2 id="i-would-like-to-share-my-project-and-interesting-papers-i-read">üë®‚Äçüíª I would like to share my project and interesting papers I read.</h2>
<h2 id="contact-info-cli38ncsueducom">üì¨ Contact info: cli38@ncsu.edu.com</h2>
]]></content>
    </entry>
</feed>