<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://chenli235.github.io</id>
    <title>Chen Li</title>
    <updated>2020-03-27T05:41:11.618Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://chenli235.github.io"/>
    <link rel="self" href="https://chenli235.github.io/atom.xml"/>
    <subtitle>UNC &amp; NCSU Biomedical Imaging Lab</subtitle>
    <logo>https://chenli235.github.io/images/avatar.png</logo>
    <icon>https://chenli235.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, Chen Li</rights>
    <entry>
        <title type="html"><![CDATA[Journal club2: Deconvolution of light sheet microscopy recordings]]></title>
        <id>https://chenli235.github.io/post/journal-club2-deconvolution-of-light-sheet-microscopy-recordings/</id>
        <link href="https://chenli235.github.io/post/journal-club2-deconvolution-of-light-sheet-microscopy-recordings/">
        </link>
        <updated>2020-03-23T16:37:00.000Z</updated>
        <content type="html"><![CDATA[<p>This paper can be found in <a href="https://www.nature.com/articles/s41598-019-53875-y">there</a></p>
<h1 id="introduction-of-psf">Introduction of PSF</h1>
<p><img src="https://chenli235.github.io/post-images/1585286735808.PNG" alt="" loading="lazy"><br>
The image formation is described above. the microscope image can be thought as the real image f convolved with PSF function h, which shows blurring effect, and add some background noises <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">ϵ</span></span></span></span>.<br>
The PSF function can be measured in two ways:</p>
<ul>
<li>Calculating a theoretical PSF, obtained from microscopic parameters</li>
<li>Recording of fluorescent beads</li>
</ul>
<h1 id="the-deconvolutiong-algorithm">The deconvolutiong algorithm</h1>
<p>Deconvolution is a mathematical operation used in Image Restoration to recover an image that is degraded by a process than can be described with a Convolution.<br>
<img src="https://chenli235.github.io/post-images/1585284966915.PNG" alt="" loading="lazy"><br>
The algorithm they use is Richardson–Lucy algorithm.</p>
<h1 id="result-from-the-paper">Result from the paper</h1>
<figure data-type="image" tabindex="1"><img src="https://chenli235.github.io/post-images/1585286234203.PNG" alt="" loading="lazy"></figure>
<h1 id="advantages">Advantages</h1>
<ol>
<li>Open source packages, easy to use.</li>
<li>No need to calculate the PSF function, just need the parameters of the microscope.</li>
<li>Showing good results on light sheet microscope.</li>
</ol>
<h1 id="result-from-cleared-bone-data">Result from cleared bone data</h1>
<p><img src="https://chenli235.github.io/post-images/1585285215106.PNG" alt="single image" title="single image Left: raw image, Right: deconv image" loading="lazy">single image Left: raw image, Right: deconv image</div><br>
<img src="https://chenli235.github.io/post-images/1585286009835.PNG" alt="z projection image" loading="lazy">z projection image Left: raw imageRight: deconv image</div></p>
<p>From the result, we notice that when using on one single image, the image will show some pepper noise due to the magnifing of noises, however, we apply the algorithm on whole z-stack and get the z-projection image, the noises will be averaged and gone.</p>
<h1 id="refrence">Refrence</h1>
<blockquote>
<p>Becker, Klaus, et al. &quot;Deconvolution of light sheet microscopy recordings.&quot; Scientific reports 9.1 (2019): 1-14.</p>
</blockquote>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mouse brain image using light sheet microscope]]></title>
        <id>https://chenli235.github.io/post/mouse-brain-image-using-light-sheet-microscope/</id>
        <link href="https://chenli235.github.io/post/mouse-brain-image-using-light-sheet-microscope/">
        </link>
        <updated>2020-03-20T01:34:17.000Z</updated>
        <content type="html"><![CDATA[<h1 id="hardware-setup">Hardware setup</h1>
<p><img src="https://chenli235.github.io/post-images/1585272993095.PNG" alt="" loading="lazy"><br>
<img src="https://chenli235.github.io/post-images/1585273628791.PNG" alt="" loading="lazy"></p>
<h1 id="mouse-brain-image">Mouse brain image</h1>
<p><img src="https://chenli235.github.io/post-images/1585275613220.PNG" alt="" loading="lazy"><br>
some common problem with light sheet microscope</p>
<ol>
<li>Intensity discontinuity<br>
<img src="https://chenli235.github.io/post-images/1585275853344.PNG" alt="" loading="lazy"><br>
it is due to the light bleaching and scattering.</li>
<li>Light Peneration issues (when using only one light path)<br>
<img src="https://chenli235.github.io/post-images/1585275983813.PNG" alt="" loading="lazy"><br>
<img src="https://chenli235.github.io/post-images/1585276033521.PNG" alt="" loading="lazy"></li>
</ol>
<h1 id="end">end</h1>
<p>it is my first experience with light sheet microscope, and I know the quality of image is not good enough. I will try different ways to improve the image quality and processing speed.</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Journal club1: Assessing microscope image focus quality with deep learning]]></title>
        <id>https://chenli235.github.io/post/articles/</id>
        <link href="https://chenli235.github.io/post/articles/">
        </link>
        <updated>2020-03-19T21:02:25.000Z</updated>
        <content type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://chenli235.github.io/post-images/1585256740222.PNG" alt="" loading="lazy"></figure>
<h1 id="intereting-paper-about-assessing-microscope-image-quality">intereting paper about assessing microscope image quality</h1>
<p>this is the <a href="https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-018-2087-4">paper</a><br>
The advantage of the proposed method:</p>
<ol>
<li>Create dataset using only in-focus images, get out-of focus images by PSF.</li>
<li>we can generate dataset of different level of focus quality by moving focus distance.</li>
<li>directly neural network and source code are provided in this article.</li>
<li>the whole image can be divided into many small image pathes,  which accelerate the training speed.</li>
<li>the method has a imageJ plugin.</li>
<li>Data augmentation to handle noises and offset images</li>
</ol>
<h1 id="implementation">Implementation</h1>
<ol>
<li>Create an dataset of images consisting of both infocus and out of focus images of U2OS cancer cells with Hoechst stain.</li>
<li>Then defocus the infocus images by applying a convolution with the PSF(point spread function) by varying z in 2um increments.<br>
<img src="https://chenli235.github.io/post-images/1585258360693.PNG" alt="PSF" loading="lazy"><br>
J0 is the Bessel function, wavelength,numerical aperture, which are related with actual setup.</li>
<li>Apply Poisson noise, accounting for sensor offset.</li>
<li>Randomly pick 84$\times<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>84</mn><mi>i</mi><mi>m</mi><mi>a</mi><mi>g</mi><mi>e</mi><mi>c</mi><mi>r</mi><mi>o</mi><mi>p</mi><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>h</mi><mi>e</mi><mn>696</mn></mrow><annotation encoding="application/x-tex">84 image crops of the 696</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord">8</span><span class="mord">4</span><span class="mord mathdefault">i</span><span class="mord mathdefault">m</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord mathdefault">e</span><span class="mord mathdefault">c</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">o</span><span class="mord mathdefault">p</span><span class="mord mathdefault">s</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mord mathdefault">t</span><span class="mord mathdefault">h</span><span class="mord mathdefault">e</span><span class="mord">6</span><span class="mord">9</span><span class="mord">6</span></span></span></span>\times$520 original size image for training, for each patch, has 11 defocus levels.<br>
<img src="https://chenli235.github.io/post-images/1585260331255.PNG" alt="good image and defocused image" loading="lazy"></li>
</ol>
<p>the neural network model architecture and some of the result<br>
<a href="https://media.springernature.com/full/springer-static/image/art%3A10.1186%2Fs12859-018-2087-4/MediaObjects/12859_2018_2087_Fig2_HTML.gif?as=webp"></a><br>
The patch outlines have one of 11 hues denoting the predicted defocus level and increasing lightness denoting increased certainty.</p>
<h1 id="results">Results</h1>
<p><a href="https://media.springernature.com/full/springer-static/image/art%3A10.1186%2Fs12859-018-2087-4/MediaObjects/12859_2018_2087_Fig7_HTML.gif?as=webp"></a><br>
Prediction of absolute focus quality on an unseen cell type (MCF-7 cells, from BBBC021 dataset [12]) and unseen stain, Tubulin, using our Fiji (ImageJ) [20] plugin with pre-trained TensorFlow model. A composite image montage was assembled using the center 84 × 84 patch from a randomly selected batch of 240 images. The border hues denote predicted defocus levels (red for best focus), while the lightness denotes prediction certainty.</p>
<h1 id="check-the-mouse-brain-image-using-the-imagej-plugin">Check the mouse brain image using the imageJ plugin</h1>
<figure data-type="image" tabindex="2"><img src="https://chenli235.github.io/post-images/1585268654621.PNG" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="3"><img src="https://chenli235.github.io/post-images/1585268819733.PNG" alt="" loading="lazy"></figure>
<p>From the result, we can get the conclusion that on images patch that have shape edges, the prediction looks good but if the signal is too strong or protein material, it may predict as a out-of-focus image.</p>
<h1 id="reference">Reference</h1>
<blockquote>
<p>Yang, S.J., Berndl, M., Michael Ando, D. et al. Assessing microscope image focus quality with deep learning. BMC Bioinformatics 19, 77 (2018). https://doi.org/10.1186/s12859-018-2087-4</p>
</blockquote>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[About me]]></title>
        <id>https://chenli235.github.io/post/about/</id>
        <link href="https://chenli235.github.io/post/about/">
        </link>
        <updated>2019-01-22T18:09:48.000Z</updated>
        <content type="html"><![CDATA[<blockquote>
<p>Welcome to my blog, nice to meet you here.</p>
</blockquote>
<h2 id="i-am-a-phd-student-in-unc-ncsu-state-joint-department-of-biomedical-engineering-my-research-area-is-medical-imging-and-microscope-design">🏠 I am a PhD student in UNC &amp; NCSU State joint Department of  Biomedical Engineering. My research area is medical imging and microscope design.</h2>
<h2 id="i-would-like-to-share-my-project-and-interesting-papers-i-read">👨‍💻 I would like to share my project and interesting papers I read.</h2>
<h2 id="contact-info-cli38ncsueducom">📬 Contact info: cli38@ncsu.edu.com</h2>
]]></content>
    </entry>
</feed>