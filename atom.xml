<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://chenli235.github.io</id>
    <title>Chen Li</title>
    <updated>2020-03-27T01:22:34.259Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://chenli235.github.io"/>
    <link rel="self" href="https://chenli235.github.io/atom.xml"/>
    <subtitle>UNC &amp; NCSU Biomedical Imaging Lab</subtitle>
    <logo>https://chenli235.github.io/images/avatar.png</logo>
    <icon>https://chenli235.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, Chen Li</rights>
    <entry>
        <title type="html"><![CDATA[Assessing microscope image focus quality with deep learning]]></title>
        <id>https://chenli235.github.io/post/assessing-microscope-image-focus-quality-with-deep-learning/</id>
        <link href="https://chenli235.github.io/post/assessing-microscope-image-focus-quality-with-deep-learning/">
        </link>
        <updated>2020-03-24T09:02:25.000Z</updated>
        <content type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://chenli235.github.io/post-images/1585256740222.PNG" alt="" loading="lazy"></figure>
<h1 id="intereting-paper-about-assessing-microscope-image-quality">intereting paper about assessing microscope image quality</h1>
<p>this is the <a href="https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-018-2087-4">paper</a><br>
The advantage of the proposed method:</p>
<ol>
<li>Create dataset using only in-focus images, get out-of focus images by PSF.</li>
<li>we can generate dataset of different level of focus quality by moving focus distance.</li>
<li>directly neural network and source code are provided in this article.</li>
<li>the whole image can be divided into many small image pathes,  which accelerate the training speed.</li>
<li>the method has a imageJ plugin.</li>
<li>Data augmentation to handle noises and offset images</li>
</ol>
<h1 id="implementation">Implementation</h1>
<ol>
<li>Create an dataset of images consisting of both infocus and out of focus images of U2OS cancer cells with Hoechst stain.</li>
<li>Then defocus the infocus images by applying a convolution with the PSF(point spread function) by varying z in 2um increments.<br>
<img src="https://chenli235.github.io/post-images/1585258360693.PNG" alt="PSF" loading="lazy"><br>
J0 is the Bessel function, wavelength,numerical aperture, which are related with actual setup.</li>
<li>Apply Poisson noise, accounting for sensor offset.</li>
<li>Randomly pick 84$\times<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>84</mn><mi>i</mi><mi>m</mi><mi>a</mi><mi>g</mi><mi>e</mi><mi>c</mi><mi>r</mi><mi>o</mi><mi>p</mi><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>h</mi><mi>e</mi><mn>696</mn></mrow><annotation encoding="application/x-tex">84 image crops of the 696</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord">8</span><span class="mord">4</span><span class="mord mathdefault">i</span><span class="mord mathdefault">m</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord mathdefault">e</span><span class="mord mathdefault">c</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">o</span><span class="mord mathdefault">p</span><span class="mord mathdefault">s</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mord mathdefault">t</span><span class="mord mathdefault">h</span><span class="mord mathdefault">e</span><span class="mord">6</span><span class="mord">9</span><span class="mord">6</span></span></span></span>\times$520 original size image for training, for each patch, has 11 defocus levels.<br>
<img src="https://chenli235.github.io/post-images/1585260331255.PNG" alt="good image and defocused image" loading="lazy"></li>
</ol>
<p>the neural network model architecture and some of the result<br>
<a href="https://media.springernature.com/full/springer-static/image/art%3A10.1186%2Fs12859-018-2087-4/MediaObjects/12859_2018_2087_Fig2_HTML.gif?as=webp"></a><br>
The patch outlines have one of 11 hues denoting the predicted defocus level and increasing lightness denoting increased certainty.</p>
<h1 id="results">Results</h1>
<p><a href="https://media.springernature.com/full/springer-static/image/art%3A10.1186%2Fs12859-018-2087-4/MediaObjects/12859_2018_2087_Fig7_HTML.gif?as=webp"></a><br>
Prediction of absolute focus quality on an unseen cell type (MCF-7 cells, from BBBC021 dataset [12]) and unseen stain, Tubulin, using our Fiji (ImageJ) [20] plugin with pre-trained TensorFlow model. A composite image montage was assembled using the center 84 × 84 patch from a randomly selected batch of 240 images. The border hues denote predicted defocus levels (red for best focus), while the lightness denotes prediction certainty.</p>
<h1 id="check-the-mouse-brain-image-using-the-imagej-plugin">Check the mouse brain image using the imageJ plugin</h1>
<figure data-type="image" tabindex="2"><img src="https://chenli235.github.io/post-images/1585268654621.PNG" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="3"><img src="https://chenli235.github.io/post-images/1585268819733.PNG" alt="" loading="lazy"></figure>
<p>From the result, we can get the conclusion that on images patch that have shape edges, the prediction looks good but if the signal is too strong or protein material, it may predict as a out-of-focus image.</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[About me]]></title>
        <id>https://chenli235.github.io/post/about/</id>
        <link href="https://chenli235.github.io/post/about/">
        </link>
        <updated>2019-01-23T20:09:48.000Z</updated>
        <content type="html"><![CDATA[<blockquote>
<p>Welcome to my blog, nie cto meet you here.</p>
</blockquote>
<h2 id="i-am-a-phd-student-in-unc-ncsu-state-joint-department-of-biomedical-engineering-my-research-area-is-medical-imging-and-microscope-design">🏠 I am a PhD student in UNC &amp; NCSU State joint Department of  Biomedical Engineering. My research area is medical imging and microscope design.</h2>
<h2 id="i-would-like-to-share-my-project-and-papers-i-read">👨‍💻 I would like to share my project and papers I read.</h2>
<h2 id="contact-info-cli38ncsueducom">📬 Contact info: cli38@ncsu.edu.com</h2>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hello Gridea]]></title>
        <id>https://chenli235.github.io/post/hello-gridea/</id>
        <link href="https://chenli235.github.io/post/hello-gridea/">
        </link>
        <updated>2018-12-11T16:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p>👏  欢迎使用 <strong>Gridea</strong> ！<br>
✍️  <strong>Gridea</strong> 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ...</p>
]]></summary>
        <content type="html"><![CDATA[<p>👏  欢迎使用 <strong>Gridea</strong> ！<br>
✍️  <strong>Gridea</strong> 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ...</p>
<!-- more -->
<p><a href="https://github.com/getgridea/gridea">Github</a><br>
<a href="https://gridea.dev/">Gridea 主页</a><br>
<a href="http://fehey.com/">示例网站</a></p>
<h2 id="特性">特性👇</h2>
<p>📝  你可以使用最酷的 <strong>Markdown</strong> 语法，进行快速创作</p>
<p>🌉  你可以给文章配上精美的封面图和在文章任意位置插入图片</p>
<p>🏷️  你可以对文章进行标签分组</p>
<p>📋  你可以自定义菜单，甚至可以创建外部链接菜单</p>
<p>💻  你可以在 <strong>Windows</strong>，<strong>MacOS</strong> 或 <strong>Linux</strong> 设备上使用此客户端</p>
<p>🌎  你可以使用 <strong>𝖦𝗂𝗍𝗁𝗎𝖻 𝖯𝖺𝗀𝖾𝗌</strong> 或 <strong>Coding Pages</strong> 向世界展示，未来将支持更多平台</p>
<p>💬  你可以进行简单的配置，接入 <a href="https://github.com/gitalk/gitalk">Gitalk</a> 或 <a href="https://github.com/SukkaW/DisqusJS">DisqusJS</a> 评论系统</p>
<p>🇬🇧  你可以使用<strong>中文简体</strong>或<strong>英语</strong></p>
<p>🌁  你可以任意使用应用内默认主题或任意第三方主题，强大的主题自定义能力</p>
<p>🖥  你可以自定义源文件夹，利用 OneDrive、百度网盘、iCloud、Dropbox 等进行多设备同步</p>
<p>🌱 当然 <strong>Gridea</strong> 还很年轻，有很多不足，但请相信，它会不停向前 🏃</p>
<p>未来，它一定会成为你离不开的伙伴</p>
<p>尽情发挥你的才华吧！</p>
<p>😘 Enjoy~</p>
]]></content>
    </entry>
</feed>